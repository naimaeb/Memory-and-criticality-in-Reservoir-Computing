{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc64d9b",
   "metadata": {},
   "source": [
    "# Effects of criticality on short term memory in a Reservoir Computing network\n",
    "\n",
    "This notebook investigates the effects of network criticality (in terms of network parameters) on tasks that require shrot term memory, namely direct memory retrieval and a 3-bit parity task (non-linear computation). The network used is a Reservoir Computing network (RNN with fixed weights and only a traineable output layer) where the encoder weights and network weights are initialized following Gaussian distributions with 0 mean and a given variance. The details of how the networks were trained is explained in the thesis and can be seen in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import scipy.stats as sps\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.integrate as integrate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from scipy.io import loadmat\n",
    "from sklearn.linear_model import RidgeClassifier, LinearRegression\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09a473f",
   "metadata": {},
   "source": [
    "# 1. Model set up\n",
    "\n",
    "The following class defines the parameters and strucutre of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55648ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_setup(skl.base.BaseEstimator, skl.base.TransformerMixin):\n",
    "    def __init__(self,n_spins, K, var_w , var_e):\n",
    "\n",
    "        self.n_spins = n_spins\n",
    "        self.K = K #number of units projecting to each spin\n",
    "        self.var_w = var_w #variance of weights, gaussain with 0 mean\n",
    "        self.var_e = var_e #variance of encoder, gaussain with 0 mean\n",
    "        \n",
    "    def setConnectivity(self):\n",
    "\n",
    "        rows = np.repeat(np.arange(self.n_spins),self.K)\n",
    "        cols = np.array([])\n",
    "        \n",
    "        for i in range(self.n_spins):\n",
    "            idx = np.random.choice(self.n_spins, self.K, replace = False)\n",
    "            cols = np.append(cols,idx).astype(int)\n",
    "        \n",
    "        data = np.ones(self.n_spins*self.K)\n",
    "        \n",
    "        C_mat = csr_matrix((data, (rows, cols)), shape=(self.n_spins, self.n_spins))\n",
    "               \n",
    "        C_mat.setdiag(0,k=0)#no self connectivity in the model        \n",
    "        return C_mat\n",
    "    \n",
    "    def setWeights(self):\n",
    "\n",
    "        C_mat = self.setConnectivity()#connectivity matrix\n",
    "        \n",
    "        \n",
    "        rows, cols = C_mat.nonzero()\n",
    "        J_mat = C_mat.copy()\n",
    "        \n",
    "        for i,j in zip(rows,cols):\n",
    "            J_mat[i,j] =np.random.normal(0, np.sqrt(self.var_w))\n",
    "            #J_mat[i,j] = (np.random.randint(2)*2 -1)\n",
    "        return J_mat\n",
    "    \n",
    "    def setEncoder(self):\n",
    "        '''\n",
    "        Generate the encoder\n",
    "        '''\n",
    "        encoder = np.random.normal(0, np.sqrt(self.var_e), self.n_spins)\n",
    "        return encoder  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913cabcf",
   "metadata": {},
   "source": [
    "# 2. Running the model\n",
    "\n",
    "The following class runs the network for a given period of time and observes its evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e374f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_run(skl.base.BaseEstimator, skl.base.TransformerMixin):\n",
    "    def __init__(self, n_spins, J, enc, mean_u = 0,  r = 0.5, encoder = True):\n",
    "            \n",
    "        self.n_spins = n_spins\n",
    "        self.r = r #rate of input u(.)\n",
    "        self.mean_u = mean_u\n",
    "        self.J = J\n",
    "        self.enc = enc\n",
    "        self.encoder = encoder #boolean statement of whether to have an encoder or not\n",
    "        self.spins = np.random.randint(2,size = self.n_spins)*2 -1 #initialize the network configuration\n",
    "        \n",
    "\n",
    "    def generateInput(self, time_steps):\n",
    "        '''\n",
    "        Generate one input variable\n",
    "        '''\n",
    "        u_t = np.random.binomial(1, self.r, time_steps)*2-1 + self.mean_u #generate random input at time t\n",
    "        \n",
    "        return u_t\n",
    "    \n",
    "    def updateSpins(self, u):\n",
    "        '''\n",
    "        Updates the nodes as a Heavised step funciton, returns also the input.\n",
    "        '''\n",
    "        \n",
    "        if self.encoder == True:\n",
    "            u_t = self.enc*u\n",
    "            \n",
    "        else:   \n",
    "            u_t = u\n",
    "        \n",
    "        h = self.J@self.spins + u_t\n",
    "        \n",
    "        #spin update, if h >= 0, set x(t) to 1, else set to 0\n",
    "        temp_nodes = np.ones(self.n_spins)\n",
    "        idx = np.where(h<0)\n",
    "        temp_nodes[idx] = -1\n",
    "        \n",
    "        self.spins = temp_nodes\n",
    "        \n",
    "        return temp_nodes #just for sanity check, remove later\n",
    "    \n",
    "    def runsim(self, t_time):\n",
    "        '''\n",
    "        Run the simulation for t_time time steps and save the state of the network\n",
    "        '''\n",
    "        \n",
    "        data = np.zeros((self.n_spins, t_time)) #empty matrix where each column is the state of the network at time t\n",
    "        u_input = self.generateInput(t_time) #generate input for t time steps\n",
    "        u_input_parity = u_input[0:-2]*u_input[1:-1]*u_input[2:]#generate the xor of the input\n",
    "        \n",
    "        for i, u in enumerate(u_input):\n",
    "            spins_t = self.updateSpins(u)\n",
    "            #print(np.dot(spins_t, self.spins)/self.n_spins)\n",
    "            data[:,i] = self.spins\n",
    "        \n",
    "        return data, u_input, u_input_parity\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff10262",
   "metadata": {},
   "source": [
    "# 3. Train and test the model\n",
    "\n",
    "The following class trains and tests the network (for a given set of parameters) on the direct memory task and on the 3-bit parity task. The parameters define how far and to what side of the critical line the network is operating in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be9f5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_results(skl.base.BaseEstimator, skl.base.TransformerMixin):\n",
    "    def __init__(self, K, tau, var_e, task, var_w, n_spins = 300, time_train = 1000, time_test = 500,  \n",
    "                 burn_t = 500, num_init = 10, num_iter = 50, n_pert = 10, var_in = False):\n",
    "            \n",
    "        self.K = K\n",
    "        self.tau = tau\n",
    "        self.var_e = var_e\n",
    "        \n",
    "        self.var_in = var_in #if true give inputs for variance, otherwise generate them in the class\n",
    "        self.var_w_list = var_w #if you want to give in specific var_w values\n",
    "        \n",
    "        self.var_w = self.critical_line_encoder() #initialize, then use critical line values\n",
    "        self.n_spins = n_spins\n",
    "        self.time_train = time_train\n",
    "        self.time_test = time_test\n",
    "        self.burn_t = burn_t\n",
    "        self.num_init = num_init\n",
    "        self.num_iter = num_iter\n",
    "        self.n_pert= n_pert \n",
    "        #task type, can either be xor or direct memory\n",
    "        self.task = task\n",
    "        \n",
    "    \n",
    "    def shift_dataset(self,X, y, t, b_t):\n",
    "        '''\n",
    "        Pairs state of the network at time t with input at time t-tau\n",
    "        '''\n",
    "        X_shift = X[:,b_t+t:]\n",
    "        y_shift = y[b_t:-t]\n",
    "\n",
    "        return X_shift, y_shift\n",
    "    \n",
    "    def generate_data(self, t, w):\n",
    "    \n",
    "        #initialize the trianing and test sets\n",
    "        X_train = np.zeros((self.n_spins,1))\n",
    "        y_train = np.zeros(1)\n",
    "        X_test = np.zeros((self.n_spins,1))\n",
    "        y_test = np.zeros(1)\n",
    "        \n",
    "        #generate the network\n",
    "        RNN = RNN_setup(n_spins = self.n_spins, K = self.K, var_w = w, var_e = self.var_e) \n",
    "        #get the weight matrix\n",
    "        J_mat = RNN.setWeights()\n",
    "        #get the encoder vector\n",
    "        enc = RNN.setEncoder() \n",
    "\n",
    "        for ni in range(self.num_init):\n",
    "        #run two separate networks\n",
    "            RNN_r1 = RNN_run(self.n_spins, J_mat, enc, encoder = True)\n",
    "            RNN_r2 = RNN_run(self.n_spins, J_mat, enc, encoder = True)\n",
    "            \n",
    "            #for the direct memory task select the direct input as the labels\n",
    "            if task == \"direct_memory\":\n",
    "                X1, u1, u1_par = RNN_r1.runsim(self.time_train+self.burn_t)\n",
    "                X2, u2, u2_par = RNN_r2.runsim(self.time_test+self.burn_t)            \n",
    "                X_tr, y_tr = self.shift_dataset(X1, u1, t, self.burn_t)\n",
    "                X_te, y_te = self.shift_dataset(X2, u2, t, self.burn_t)\n",
    "            \n",
    "            #for the xor task select the xor of the input as the labels\n",
    "            if task == \"3parity\":  \n",
    "                X1, u1, u1_par = RNN_r1.runsim(self.time_train+self.burn_t)\n",
    "                X2, u2, u2_par = RNN_r2.runsim(self.time_test+self.burn_t)\n",
    "                #as the xor of the input has one less index, remove first instance of the data (does not compute xor)\n",
    "                X_tr, y_tr = self.shift_dataset(X1[:,2:], u1_par, t, self.burn_t)\n",
    "                X_te, y_te = self.shift_dataset(X2[:,2:], u2_par, t, self.burn_t)\n",
    "\n",
    "\n",
    "            X_train = np.concatenate((X_train, X_tr), axis = 1)\n",
    "            X_test = np.concatenate((X_test, X_te), axis = 1)\n",
    "            y_train = np.concatenate((y_train, y_tr))\n",
    "            y_test = np.concatenate((y_test, y_te))\n",
    "        \n",
    "        #remove all the initialization zeros\n",
    "        return X_train[:,1:].T, y_train[1:], X_test[:,1:].T, y_test[1:], u1_par, u1\n",
    "    \n",
    "    \n",
    "    def critical_line_encoder(self):\n",
    "        '''\n",
    "        Takes in a set of sigma_e (standard deviation for the encoder) values and computes the corresponding \n",
    "        sigma_w vales at criticality.\n",
    "        '''\n",
    "        \n",
    "        sigma_e = np.sqrt(self.var_e)\n",
    "        sigma_w_val = 0\n",
    "\n",
    "        tan_arg = np.tan(np.pi/(2*self.K)) #tangent expression       \n",
    "        sigma_w_val = (sigma_e*tan_arg)/(np.sqrt(1- self.K*(tan_arg**2) + (tan_arg**2)))\n",
    "        \n",
    "        #returns the variance of the network weights\n",
    "        return sigma_w_val**2\n",
    "        \n",
    "\n",
    "    def train_test_tau(self):\n",
    "        '''\n",
    "        Train and test the network for differen tau values and fixed ratio of sigma_e, sigma_w.\n",
    "        '''\n",
    "        if self.var_in == True:\n",
    "            print(\"True\")\n",
    "            var_w_perturbations = self.var_w_list\n",
    "        else:\n",
    "            print(\"False\")\n",
    "            var_w_perturbations = np.linspace(self.var_w - 0.7*self.var_w, self.var_w+0.2*self.var_w, self.n_pert)\n",
    "\n",
    "        #initialize scores\n",
    "        mean_accuracy = np.zeros((var_w_perturbations.shape[0],self.tau.shape[0], self.num_iter))\n",
    "        MI_score = np.zeros((var_w_perturbations.shape[0],self.tau.shape[0], self.num_iter))\n",
    "        \n",
    "        #loop over sigma_w values and tau\n",
    "        for it in range(self.num_iter):\n",
    "            for i, w in enumerate(var_w_perturbations):\n",
    "                for j, t in enumerate(self.tau):\n",
    "\n",
    "                    X_train, y_train, X_test, y_test, u1_par, u1 = self.generate_data(t, w)#generate the data to trian the network\n",
    "                    \n",
    "                    #fit the linear decoder: using Ridge regression\n",
    "                    clf = RidgeClassifier().fit(X_train, y_train)\n",
    "                    \n",
    "                    #compute the mean accuracy and normalized MI scores\n",
    "                    mean_accuracy[i,j, it] = clf.score(X_test, y_test)\n",
    "                    MI_score[i,j, it] = skl.metrics.normalized_mutual_info_score(y_test, clf.predict(X_test))\n",
    "                    \n",
    "\n",
    "        return mean_accuracy, MI_score, var_w_perturbations, self.var_w, u1_par, u1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c5973c",
   "metadata": {},
   "source": [
    "# 4. Results on the direct memory task\n",
    "\n",
    "Train the network for different parameters (different distances from the critical line) and look at the results on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ba8a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 8\n",
    "n_spins = 300\n",
    "tau = np.arange(9)+1\n",
    "var_w = np.array([0.137, 0.274, 0.301])\n",
    "var_e = 5\n",
    "sigma_e_critical = np.array([np.sqrt(var_e)])\n",
    "perturbations = 10\n",
    "it = 50\n",
    "task = \"direct_memory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501099c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_r = RNN_results(K, tau, var_e, task, var_w, n_spins = n_spins, time_train = 1000, time_test = 500,  \n",
    "                 burn_t = 500, num_init = 10, num_iter = it, n_pert = perturbations, var_in = True)\n",
    "\n",
    "mean_accuracy, MI_score, var_w_perturbed, var_w_critical, u_par, u = RNN_r.train_test_tau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba116254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to data in gonzaga\n",
    "\n",
    "path = \"/home/elosegui/MSc_thesis_project/numpy_results/direct_memory_task/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aca4cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the files\n",
    "np.save(path+\"accuracy_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e), mean_accuracy)\n",
    "np.save(path+\"MI_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e), MI_score)\n",
    "np.save(path+\"var_w_perturbed_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e), var_w_perturbed)\n",
    "np.save(path+\"var_w_critical_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e), var_w_critical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a212db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "mean_accuracy = np.load(path+\"accuracy_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e)+\".npy\")\n",
    "MI_score = np.load(path+\"MI_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e)+\".npy\")\n",
    "var_w_perturbed = np.load(path+\"var_w_perturbed_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e)+\".npy\")\n",
    "var_w_critical = np.load(path+\"var_w_critical_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e)+\".npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc6853",
   "metadata": {},
   "source": [
    "### 4.1 Preliminary plots to look at the mean over trials of the MI score and the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5328cf24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "MI_mean = np.mean(MI_score, axis = 2)\n",
    "MI_std = np.std(MI_score, axis = 2)\n",
    "\n",
    "acc_mean = np.mean(mean_accuracy, axis = 2)\n",
    "acc_std = np.std(mean_accuracy, axis = 2)\n",
    "\n",
    "plt.plot(tau,acc_mean.T)\n",
    "plt.xlabel(\"tau\")\n",
    "plt.ylabel(\"Mean acuracy score\")\n",
    "plt.title(\"Mean acuracy for varying distances from the critical line\")\n",
    "#plt.legend([\"Letter condition\", allLetters[i] for i in range(0,10)])\n",
    "plt.legend([\"var_w {}\".format(np.round(w,3)) for w in var_w_perturbed], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "print(var_w_critical)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de797a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_mean = np.mean(MI_score, axis = 2)\n",
    "MI_std = np.std(MI_score, axis = 2)\n",
    "\n",
    "acc_mean = np.mean(mean_accuracy, axis = 2)\n",
    "acc_std = np.std(mean_accuracy, axis = 2)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(tau[3:5],acc_std.T[3:5,3:9])\n",
    "plt.xlabel(\"tau\")\n",
    "plt.ylabel(\"Standard deviation\")\n",
    "plt.title(\"Standard deviation for varying distances from the critical line\")\n",
    "#plt.legend([\"Letter condition\", allLetters[i] for i in range(0,10)])\n",
    "plt.legend([\"var_w {}\".format(np.round(w,3)) for w in var_w_perturbed[3:9]], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "print(var_w_critical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50378383",
   "metadata": {},
   "source": [
    "# 5. Results on the 3-bit parity task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7bffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the parameters\n",
    "\n",
    "K = 8\n",
    "n_spins = 300\n",
    "tau = np.arange(9)+1\n",
    "var_e = 5\n",
    "perturbations = 10\n",
    "it = 50\n",
    "var_w = np.array([])\n",
    "task = \"3parity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae61ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test the network\n",
    "\n",
    "RNN_r = RNN_results(K, tau, var_e, task, var_w, n_spins = 300, time_train = 1000, time_test = 500,  \n",
    "                 burn_t = 500, num_init = 10, num_iter = 50, n_pert = 10, var_in = False)\n",
    "\n",
    "mean_accuracy, MI_score, var_w_perturbed, var_w_critical, u_par, u = RNN_r.train_test_tau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5a8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to data in gonzaga\n",
    "\n",
    "path = \"/home/elosegui/MSc_thesis_project/numpy_results/3bit_parity/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the files\n",
    "np.save(path+\"accuracy_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e), mean_accuracy)\n",
    "np.save(path+\"MI_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e), MI_score)\n",
    "np.save(path+\"var_w_perturbed_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e), var_w_perturbed)\n",
    "np.save(path+\"var_w_critical_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e), var_w_critical)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "mean_accuracy = np.load(path+\"accuracy_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e)+\".npy\")\n",
    "MI_score = np.load(path+\"MI_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e)+\".npy\")\n",
    "var_w_perturbed = np.load(path+\"var_w_perturbed_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e)+\".npy\")\n",
    "var_w_critical = np.load(path+\"var_w_critical_\"+\"K\" +str(K)+\"_iterations\"+str(it)+\"_N\"+str(n_spins)+\"_var_e\"+str(var_e)+\".npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f89198",
   "metadata": {},
   "source": [
    "### 5.1 Preliminary plots for the mean and standard deviation of the MI score across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_mean = np.mean(MI_score, axis = 2)\n",
    "MI_std = np.std(MI_score, axis = 2)\n",
    "\n",
    "acc_mean = np.mean(mean_accuracy, axis = 2)\n",
    "acc_std = np.std(mean_accuracy, axis = 2)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(tau,acc_mean.T[:,3:9])\n",
    "plt.xlabel(\"tau\")\n",
    "plt.ylabel(\"Mean acuracy score\")\n",
    "plt.title(\"Mean acuracy for varying distances from the critical line\")\n",
    "#plt.legend([\"Letter condition\", allLetters[i] for i in range(0,10)])\n",
    "plt.legend([\"var_w {}\".format(np.round(w,3)) for w in var_w_perturbed[3:9]], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "print(var_w_critical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_mean = np.mean(MI_score, axis = 2)\n",
    "MI_std = np.std(MI_score, axis = 2)\n",
    "\n",
    "acc_mean = np.mean(mean_accuracy, axis = 2)\n",
    "acc_std = np.std(mean_accuracy, axis = 2)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(tau[3:5],acc_std.T[3:5,3:9])\n",
    "plt.xlabel(\"tau\")\n",
    "plt.ylabel(\"Standard deviation\")\n",
    "plt.title(\"Standard deviation for varying distances from the critical line\")\n",
    "#plt.legend([\"Letter condition\", allLetters[i] for i in range(0,10)])\n",
    "plt.legend([\"var_w {}\".format(np.round(w,3)) for w in var_w_perturbed[3:9]], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "print(var_w_critical)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
